{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Raspberry Pi GitOps Stack This document describes my current setup of my Rasperry Pi k8s cluster. Although everything should be reflected in code, usually my brain discards stuff which works ... now. The not-working is a problem for future brain \ud83d\ude04 So the text is mainly meant for me to keep track of how and why I did certain things. If somebody else finds value in it: great! Although the whole thing is a private project for educational purposes, I try to keep it as production ready as possible. Often the biggest learnings stem from corner cases. That means, at least for me, to stay true to the following points: Everything is automated, no manual kubectl commands Clear separation between public and private network Use secure connections All HTTPS connections have correct certificates from LetcEncrypt Disaster recovery is easy to do Critical parts of the system (like control-plane, networking, etc) are setup in HA","title":"Home"},{"location":"#raspberry-pi-gitops-stack","text":"This document describes my current setup of my Rasperry Pi k8s cluster. Although everything should be reflected in code, usually my brain discards stuff which works ... now. The not-working is a problem for future brain \ud83d\ude04 So the text is mainly meant for me to keep track of how and why I did certain things. If somebody else finds value in it: great! Although the whole thing is a private project for educational purposes, I try to keep it as production ready as possible. Often the biggest learnings stem from corner cases. That means, at least for me, to stay true to the following points: Everything is automated, no manual kubectl commands Clear separation between public and private network Use secure connections All HTTPS connections have correct certificates from LetcEncrypt Disaster recovery is easy to do Critical parts of the system (like control-plane, networking, etc) are setup in HA","title":"Raspberry Pi GitOps Stack"},{"location":"argocd/","text":"Argo CD Part Two: OIDC integration This part should follow after [Vault] and [Authentik] are up and running. OIDC Login First you have to create a provider and application in authentik to get a client id and secret. Afterwards the oidc credentials can be saved in the Vault and mapped over a SecretProviderClass . (Do not forget to mount the vault volumes for the secret to work [./secrets-csi.md#volumes-in-a-chart]) --- apiVersion : secrets-store.csi.x-k8s.io/v1 kind : SecretProviderClass metadata : name : vault-argocd spec : provider : vault parameters : vaultAddress : \"http://vault.vault:8200\" roleName : \"argocd-app\" objects : | - objectName: \"oidc-id\" secretPath: \"kv-v2/data/framsburg/argocd/oidc\" secretKey: \"client-id\" - objectName: \"oidc-secret\" secretPath: \"kv-v2/data/framsburg/argocd/oidc\" secretKey: \"client-secret\" secretObjects : - data : - key : oidc.authentik.clientId objectName : oidc-id - key : oidc.authentik.clientSecret objectName : oidc-secret secretName : oidc type : Opaque labels : app.kubernetes.io/part-of : argocd # (1)! Without this label the secret reference in the argocd ConfigMap will not work and complain about that the secret key can not be found. argo-cd : server : ... config : url : https://argocd.framsburg.ch oidc.config : | name: Authentik issuer: \"https://authentik.framsburg.ch/application/o/argocd/\" clientID: \"c579d3195f85aeccaf1ecce35ef5501e023c2a6a\" clientSecret: \"$oidc:oidc.authentik.clientSecret\" requestedScopes: [\"openid\", \"profile\", \"email\"] logoutURL: \"https://authentik.framsburg.ch/if/session-end/argocd/\" rbacConfig : policy.default : role:readonly policy.csv : | g, 'authentik Admins', role:admin volumeMounts : - name : 'secrets-store-inline' mountPath : '/mnt/secrets-store' readOnly : true volumes : - name : secrets-store-inline csi : driver : 'secrets-store.csi.k8s.io' readOnly : true volumeAttributes : secretProviderClass : 'vault-argocd'","title":"ArgoCD"},{"location":"argocd/#argo-cd","text":"","title":"Argo CD"},{"location":"argocd/#part-two-oidc-integration","text":"This part should follow after [Vault] and [Authentik] are up and running.","title":"Part Two: OIDC integration"},{"location":"argocd/#oidc-login","text":"First you have to create a provider and application in authentik to get a client id and secret. Afterwards the oidc credentials can be saved in the Vault and mapped over a SecretProviderClass . (Do not forget to mount the vault volumes for the secret to work [./secrets-csi.md#volumes-in-a-chart]) --- apiVersion : secrets-store.csi.x-k8s.io/v1 kind : SecretProviderClass metadata : name : vault-argocd spec : provider : vault parameters : vaultAddress : \"http://vault.vault:8200\" roleName : \"argocd-app\" objects : | - objectName: \"oidc-id\" secretPath: \"kv-v2/data/framsburg/argocd/oidc\" secretKey: \"client-id\" - objectName: \"oidc-secret\" secretPath: \"kv-v2/data/framsburg/argocd/oidc\" secretKey: \"client-secret\" secretObjects : - data : - key : oidc.authentik.clientId objectName : oidc-id - key : oidc.authentik.clientSecret objectName : oidc-secret secretName : oidc type : Opaque labels : app.kubernetes.io/part-of : argocd # (1)! Without this label the secret reference in the argocd ConfigMap will not work and complain about that the secret key can not be found. argo-cd : server : ... config : url : https://argocd.framsburg.ch oidc.config : | name: Authentik issuer: \"https://authentik.framsburg.ch/application/o/argocd/\" clientID: \"c579d3195f85aeccaf1ecce35ef5501e023c2a6a\" clientSecret: \"$oidc:oidc.authentik.clientSecret\" requestedScopes: [\"openid\", \"profile\", \"email\"] logoutURL: \"https://authentik.framsburg.ch/if/session-end/argocd/\" rbacConfig : policy.default : role:readonly policy.csv : | g, 'authentik Admins', role:admin volumeMounts : - name : 'secrets-store-inline' mountPath : '/mnt/secrets-store' readOnly : true volumes : - name : secrets-store-inline csi : driver : 'secrets-store.csi.k8s.io' readOnly : true volumeAttributes : secretProviderClass : 'vault-argocd'","title":"OIDC Login"},{"location":"authentik/","text":"Authentik","title":"Authentik"},{"location":"authentik/#authentik","text":"","title":"Authentik"},{"location":"cert-manager/","text":"Cert-Manager","title":"Cert Manager"},{"location":"cert-manager/#cert-manager","text":"","title":"Cert-Manager"},{"location":"longhorn/","text":"Longhorn","title":"Longhorn"},{"location":"longhorn/#longhorn","text":"","title":"Longhorn"},{"location":"metallb/","text":"MetalLB","title":"MetalLB"},{"location":"metallb/#metallb","text":"","title":"MetalLB"},{"location":"monitoring/","text":"Monitoring with Prometheus Stack","title":"Monitoring"},{"location":"monitoring/#monitoring-with-prometheus-stack","text":"","title":"Monitoring with Prometheus Stack"},{"location":"secrets-csi/","text":"Secrets with CSI Vault Secret Injection with CSI One way to use credentials from the vault inside pods is with CSI. Vault post-start command to enable kubernetes auth-method Use Vault with CSI Install CSI Driver CRD with Chart Define a generic SecretProviderClass template as it is needed for each secret (quite a lot of boilerplate) In case you need the vault command you can easily log into the shell with: $ kubectl exec -it vault-0 -- /bin/sh Create the secrets with: $ vault kv put kv-v2/k8s/framsburg/dex client-id = \"someID\" client-secret = \"someSecret\" Enable and activate kubernetes auth method $ vault auth enable kubernetes $ vault write auth/kubernetes/config \\ issuer = \"https://kubernetes.default.svc.cluster.local\" \\ token_reviewer_jwt = \" $( cat /var/run/secrets/kubernetes.io/serviceaccount/token ) \" \\ kubernetes_host = \"https:// $KUBERNETES_PORT_443_TCP_ADDR :443\" \\ kubernetes_ca_cert = @/var/run/secrets/kubernetes.io/serviceaccount/ca.crt Create a policy: $ vault policy write dex-app - <<EOF policy dex-app: path \"kv-v2/data/k8s/framsburg/dex\" { capabilities = [\"read\"] } EOF Write a role to map a service account with a policy $ vault write auth/kubernetes/role/dex-app \\ bound_service_account_names = dex \\ bound_service_account_namespaces = dex \\ policies = dex-app \\ ttl = 20m Success! Data written to: auth/kubernetes/role/dex-app Secret Class --- apiVersion : secrets-store.csi.x-k8s.io/v1 kind : SecretProviderClass metadata : name : vault-dex spec : provider : vault parameters : vaultAddress : \"http://vault.vault:8200\" roleName : \"dex-app\" objects : | - objectName: \"oidc-id\" secretPath: \"kv-v2/data/k8s/framsburg/dex\" secretKey: \"client-id\" - objectName: \"oidc-secret\" secretPath: \"kv-v2/data/k8s/framsburg/dex\" secretKey: \"client-secret\" secretObjects : - data : - key : id objectName : oidc-id - key : secret objectName : oidc-secret secretName : oidc type : Opaque Volumes in a Chart ... env : - name : GITHUB_CLIENT_ID valueFrom : secretKeyRef : name : oidc key : id - name : GITHUB_CLIENT_SECRET valueFrom : secretKeyRef : name : oidc key : secret envFrom : - secretRef : name : oidc ... volumeMounts : - name : 'secrets-store-inline' mountPath : '/mnt/secrets-store' readOnly : true volumes : - name : secrets-store-inline csi : driver : secrets-store.csi.k8s.io readOnly : true volumeAttributes : secretProviderClass : vault-dex","title":"Secrets-CSI"},{"location":"secrets-csi/#secrets-with-csi","text":"","title":"Secrets with CSI"},{"location":"secrets-csi/#vault-secret-injection-with-csi","text":"One way to use credentials from the vault inside pods is with CSI. Vault post-start command to enable kubernetes auth-method Use Vault with CSI Install CSI Driver CRD with Chart Define a generic SecretProviderClass template as it is needed for each secret (quite a lot of boilerplate) In case you need the vault command you can easily log into the shell with: $ kubectl exec -it vault-0 -- /bin/sh Create the secrets with: $ vault kv put kv-v2/k8s/framsburg/dex client-id = \"someID\" client-secret = \"someSecret\" Enable and activate kubernetes auth method $ vault auth enable kubernetes $ vault write auth/kubernetes/config \\ issuer = \"https://kubernetes.default.svc.cluster.local\" \\ token_reviewer_jwt = \" $( cat /var/run/secrets/kubernetes.io/serviceaccount/token ) \" \\ kubernetes_host = \"https:// $KUBERNETES_PORT_443_TCP_ADDR :443\" \\ kubernetes_ca_cert = @/var/run/secrets/kubernetes.io/serviceaccount/ca.crt Create a policy: $ vault policy write dex-app - <<EOF policy dex-app: path \"kv-v2/data/k8s/framsburg/dex\" { capabilities = [\"read\"] } EOF Write a role to map a service account with a policy $ vault write auth/kubernetes/role/dex-app \\ bound_service_account_names = dex \\ bound_service_account_namespaces = dex \\ policies = dex-app \\ ttl = 20m Success! Data written to: auth/kubernetes/role/dex-app","title":"Vault Secret Injection with CSI"},{"location":"secrets-csi/#secret-class","text":"--- apiVersion : secrets-store.csi.x-k8s.io/v1 kind : SecretProviderClass metadata : name : vault-dex spec : provider : vault parameters : vaultAddress : \"http://vault.vault:8200\" roleName : \"dex-app\" objects : | - objectName: \"oidc-id\" secretPath: \"kv-v2/data/k8s/framsburg/dex\" secretKey: \"client-id\" - objectName: \"oidc-secret\" secretPath: \"kv-v2/data/k8s/framsburg/dex\" secretKey: \"client-secret\" secretObjects : - data : - key : id objectName : oidc-id - key : secret objectName : oidc-secret secretName : oidc type : Opaque","title":"Secret Class"},{"location":"secrets-csi/#volumes-in-a-chart","text":"... env : - name : GITHUB_CLIENT_ID valueFrom : secretKeyRef : name : oidc key : id - name : GITHUB_CLIENT_SECRET valueFrom : secretKeyRef : name : oidc key : secret envFrom : - secretRef : name : oidc ... volumeMounts : - name : 'secrets-store-inline' mountPath : '/mnt/secrets-store' readOnly : true volumes : - name : secrets-store-inline csi : driver : secrets-store.csi.k8s.io readOnly : true volumeAttributes : secretProviderClass : vault-dex","title":"Volumes in a Chart"},{"location":"traefik/","text":"Traefik","title":"Traefik"},{"location":"traefik/#traefik","text":"","title":"Traefik"},{"location":"vault/","text":"Hashicorp Vault","title":"Hashicorp Vault"},{"location":"vault/#hashicorp-vault","text":"","title":"Hashicorp Vault"}]}